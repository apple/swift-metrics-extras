# SSM-0001: `swift-metrics-extras` revised public API to support 1.0 roadmap

As part of the 1.0 release we would like to revise the public API to simplify adoption and maintenance:
* Reduce public API to a minimum to make it easier to support more platforms and metrics gathering strategies.
* Decouple `swift-metrics-extras` public interface from the global `MetricsSystem`.
* Add compatibility with `swift-service-lifecycle`

## Overview

- Proposal: SSM-0001
- Author(s): [Vladimir Kukushkin](https://github.com/kukushechkin)
- Status: **Awaiting Review**
- Issue: [apple/swift-metrics-extras#64](https://github.com/apple/swift-metrics-extras/issues/64)
- Implementation:
    - [apple/swift-metrics-extras#64](https://github.com/apple/swift-metrics-extras/pull/64)
- Related links:
    - [Swift Evolution](https://www.swift.org/swift-evolution/)

### Introduction

This proposal aims to change the public interface of the package to bring it in line with the latest best practices in the Swift ecosystem and reduce the API to a minimum focused on automatic background gathering of system metrics for the supported platforms.

### Motivation

`swift-metrics-extras` provides only one component — `SystemMetrics`, which periodically collects process system metrics in the background. The monitoring is a separate component, which depends on the `MetricsSystem`, but is not part of it. While it is possible to use `SystemMetrics` as an independent object, the user would need to maintain its lifecycle manually, and it still requires the globally initialized `MetricsSystem`.

Coupling with the `MetricsSystem` bootstrapping is unnecessary and prevents users from using different backends for different metrics, for example, if `SystemMetrics` should be sent to a different backend. This coupling also makes it hard to unit test the package.

### Proposed solution

To solve the unnecessary coupling with the `MetricsSystem`, I propose to change the interface of the `SystemMetrics` — a new `SystemMetricsMonitor` object compatible with the `swift-service-lifecycle` `Service` protocol to run the periodic metrics collection and reporting in the background for the whole lifecycle of the parent service.

This is how it can be integrated into a service:

```
import SystemMetrics
import ServiceLifecycle
import UnixSignals
import Metrics

@main
struct Application {
    static let logger = Logger(label: "Application")
    static let metrics = MyMetricsBackendImplementation()

    static func main() async throws {
        MetricsSystem.bootstrap(metrics)

        let service = FooService()
        let systemMetricsMonitor = SystemMetricsMonitor()
        let serviceGroup = ServiceGroup(
            services: [service, systemMetricsMonitor],
            gracefulShutdownSignals: [.sigterm],
            logger: logger
        )

        try await serviceGroup.run()
    }
}
```

The proposed interface also makes the package more testable, as users can inject a mock `MetricsFactory` and verify metric collection without global state dependency.

### Detailed design

The full API of the proposed `SystemMetricsMonitor` is the following:

```
/// A monitor that periodically collects and reports system metrics.
///
/// `SystemMetricsMonitor` provides a way to automatically collect process-level system metrics
/// (such as memory usage, CPU time) and report them through the Swift Metrics API.
///
/// Example usage:
///
/// let monitor = SystemMetricsMonitor()
/// try await monitor.run()
///
@available(macOS 13.0, iOS 16.0, watchOS 9.0, tvOS 16.0, *)
public struct SystemMetricsMonitor: Service {
    /// Create a new `SystemMetricsMonitor` with a custom metrics factory.
    ///
    /// - Parameters:
    ///   - configuration: The configuration for the monitor.
    ///   - metricsFactory: The metrics factory to use for creating metrics.
    ///   - logger: A custom logger.
    public init(
        configuration: SystemMetricsMonitor.Configuration = .init(),
        metricsFactory: MetricsFactory,
        logger: Logger = Logger(label: "SystemMetricsMonitor")
    ) {...}

    /// Create a new `SystemMetricsMonitor` using the global metrics factory.
    ///
    /// - Parameters:
    ///   - configuration: The configuration for the monitor.
    ///   - logger: A custom logger.
    public init(
        configuration: SystemMetricsMonitor.Configuration = .init(),
        logger: Logger = Logger(label: "SystemMetricsMonitor")
    ) {...}

    /// Start the monitoring loop, collecting and reporting metrics at the configured interval.
    ///
    /// This method runs indefinitely, periodically collecting and reporting system metrics
    /// according to the poll interval specified in the configuration. It will only return
    /// if the async task is cancelled.
    public func run() async throws {...}
}
```

With configuration represented by the structure `SystemMetricsMonitor.Configuration`:

```
extension SystemMetricsMonitor {
    public struct Configuration: Sendable {
        /// Create new instance of `SystemMetricsMonitor.Configuration`
        ///
        /// - Parameters:
        ///     - interval: The interval at which system metrics should be updated.
        public init(
            pollInterval interval: Duration = .seconds(2)
        ) {...}
    }
}
```

### API stability

This is a breaking change in the public interface, which is acceptable as the package is currently pre-1.0.

### Future directions

Darwin and Windows support. As unit tests are now also decoupled from the global state, there is a clear way of testing platform-specific functionality when a new platform support is introduced.

In the future, it might be valuable to expose the internal `SystemMetricsProvider` to allow users to create custom implementations for collecting system metrics.

The package internals can be expanded to support multiple data providers called at different intervals to gather metrics more efficiently.

Expand the list of collected metrics, for example, following https://prometheus.io/docs/instrumenting/writing_clientlibs/#process-metrics and https://prometheus.io/docs/instrumenting/writing_clientlibs/#runtime-metrics.

### Alternatives considered

**Keep the public API and implementation as is.** In this case, we keep the public API intact, but rely on the global `MetricsSystem` bootstrapping.

**Keep all the existing customization options.** This would potentially require workarounds if new platforms, metrics or backends implementations do not support the existing model. Removed customization features like custom labels or dimensions can be added post-1.0 if this is considered necessary.
